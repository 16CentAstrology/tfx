{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# IMDB Sentiment Analaysis Example\r\n",
    "<div style=\"font-size: 15px\">\r\n",
    "<ul>\r\n",
    "<li>The data is downloaded from tensorflow_dataset.</li>\r\n",
    "<li>The example dataset imdb_small_with_labels.csv that comes within /data is</li>\r\n",
    "<li>the first 100 entries of the original dataset.</li>\r\n",
    "<li>To fetch the entire dataset, please use the snippet below</li>\r\n",
    "<li>And please adjust the corresponding hyperparameters to account for the\r\n",
    "    larger dataset.</li>\r\n",
    "</ul>\r\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<pre>\r\n",
    "<div style=\"font-size: 15px\">\r\n",
    "Run this file to download and preprocess then entire imdb dataset.<br>\r\n",
    "Remove the imdb_small_with_labels.csv that comes natively in the repo/data<br>\r\n",
    "folder. Make sure imdb.csv is present in the /data folder.<br>\r\n",
    "Change the hyperparameters to better suit the bigger dataset.<br>\r\n",
    "The configurations that were found reasonable are listed below:<br>\r\n",
    "imdb_pipeline_native_keras.py:<br>\r\n",
    "   tfma.GenericValueThreshold(lower_bound={'value':0.85}<br>\r\n",
    "   trainer_pb2.TrainArgs(num_steps=7000)<br>\r\n",
    "   trainer_pb2.EvalArgs(num_steps=800)<br>\r\n",
    "imdb_utils_native_keras.py:<br>\r\n",
    "   _TRAIN_BATCH_SIZE=64<br>\r\n",
    "   _EVAL_BATCH_SIZE=64<br>\r\n",
    "</div>\r\n",
    "</pre>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "  ds = tfds.load('imdb_reviews', split='train+test')\r\n",
    "  numpy_ds = tfds.as_numpy(ds)\r\n",
    "  df = pd.DataFrame(numpy_ds)\r\n",
    "  df['text'] = df['text'].str.decode(\"utf-8\")\r\n",
    "  dst_path = os.getcwd() + '/data/imdb.csv'\r\n",
    "  df.to_csv(dst_path, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Acknowledge Data Source\r\n",
    "\r\n",
    "```\r\n",
    "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\r\n",
    "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},<br>\r\n",
    "  title     = {Learning Word Vectors for Sentiment Analysis},<br>\r\n",
    "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},<br>\r\n",
    "  month     = {June},<br>\r\n",
    "  year      = {2011},<br>\r\n",
    "  address   = {Portland, Oregon, USA}<br>,\r\n",
    "  publisher = {Association for Computational Linguistics}<br>,\r\n",
    "  pages     = {142--150}<br>,\r\n",
    "  url       = {http://www.aclweb.org/anthology/P11-1015}<br>\r\n",
    "}"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
